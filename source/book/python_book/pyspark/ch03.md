第三章、DataFrame
==============================================
DataFrame是一种不可变的分布式数据库 这种数据库被组织成指定的列，类似于关系数据库中的表  

3.1、Python到RDD之间的通信「略」
------------------------------------------------------------------

3.2、catalyst 优化刷新「略」
------------------------------------------------------------------

3.3、利用DataFrame 加速pyspark「略」
------------------------------------------------------------------

3.4、创建DataFrame
------------------------------------------------------------------
加载json数据：
```
styringJsonRDD = sc.parallelize((
"""
    {'id':'123','name','rdd'}
"""
),"""
{'id':21,"name":'snv'}
""")
```
创建好了RDD 使用sparksession read.json方法RDD将会被转换成DataFrame 

我们还可以利用 ``createOrReplaceTempView`` 方法创建一个临时表

创建一个DataFrame： 

```
datafromjson = spark.read.json(styringJsonRDD)
```

创建一个临时表：
```
swinerjson = createOrReplaceTempView("datafromjson")
```

在前面章节提到过，旭辉哦RDD操作都是有相关转换的。直到操作执行，这些RDD操作都不会被执行。

可以使用spark UI截屏查看可视化 方便理解spark

3.5、简单的DataFrame查询
------------------------------------------------------------------

```
swinerjson.show()
#默认显示前10行

#SQL查询
spark.sql("select * from swinerjson").collect()
```

3.6 RDD 的交互操作
------------------------------------------------------------------

有两种从RDD交换到DataFrame 的不同方法： 使用反射推断模式或以编程方式制定模式

前者可以写更简洁的代码 二在列和DataFrame的数据类型是在运行时才发现的情况下。

后者则允许构建DataFrame 

```
#打印模式
swinerjson.printSchema()
```

编程指定模式：
```
from pyspark.sql.types import * 
stringCSVRDD  = sc.parallelize([(123,'knmn',19,'bb'),(124,'kn3mn',119,'bcb'),(125,'knamn',193,'b3b')])
```

首选根据以下的schema 变量将模式编码成一个字符串  然后我们会利用 StringType 和 StructField 定义模式。

```
schema = StructTyep([
    StructField('id',LongType(),True),
    StructField('name',StringType(),True),
    StructField('age',LongType(),True),
    StructField('eyeColor',StringType(),True)
])

#对RDD应用该模式并且创建DataFrame
swimmers = spark.createDataFrame(stringCSVRDD,schema)
#利用DataFrame创建一个临时视图
swimmers.createOrReplaceTempView("swimmers")

swimmers.printSchema()

```

3.7、利用 DataFrame API查询
------------------------------------------------------------------

行数： swimmers.count()

筛选获取 年龄等于22的 id和name列 ： 
```
swimmers.select("id","name").filter('age=22').show()
```

另一种筛选方式： 

```
swimmers.select(swimmers.id,swimmers.name).filter(swimmers.age==22).show()
```

获取b名字开头的名字： 
```
swimmers.select("id","name").filter("name like 'b%'").show()
```

3.8、利用SQL查询
------------------------------------------------------------------

行数： 
```
spark.sql("select count(1) from swimmers ").show()
```

where 子句筛选语句
```
spark.sql("select id,age,name from swimmers where age = 22 ").show()
```

3.9、DataFrame 场景——实时飞行性能「略」
------------------------------------------------------------------

3.10、Spark数据集(Dataset) API「略」
------------------------------------------------------------------

3.11、小结
------------------------------------------------------------------

本章 通过生成数据或者利用已经存在的数据集来创建和处理DataFrame











