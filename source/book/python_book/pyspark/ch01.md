第一章、了解spark
==============================================
spark可以解决复杂的数据问题

无论是半结构化、结构化、流式、或机器学习、数据科学

1.1、什么是Apache spark
------------------------------------------------------------------

spark是一个开源的强大的分布式查询和处理引擎。  他提供MapReduce的灵活和可扩展 比Hadoop块100倍。

spark允许用户读取、转换、聚合数据，还可以训练和部署复杂的统计模型

1.2、spark作业和api
------------------------------------------------------------------

和人spark应用程序都会分离主节点上的单个驱动进程，然后将执行进程分配给多个工作节点

驱动进程会确定任务进程的数据和组成，这些任务进程是根据指定作业生成的图形分配给执行节点的。

弹性分布式数据集 简称RDD 是不可变的Java虚拟机 对象的分布式集合 spark就是围绕着RDD而构建的。

RDD有两组并行才做： 转换(返回指向新RDD的指针)和动作(在运行计算后向驱动程序返回值)

DataFrame 像RDD一样 是分布在集群的节点中的不可变的数据集合

DataFrame旨在使大型数据的处理更加容易。它们允许开发人员对数据结构进行格式化，允许更高级的抽象。

在这个意义上来说DataFrame与关系数据库中的表类似。

DataFrame的一个主要优点是spark引擎一开始就构建了一个逻辑执行计划，而且执行生成的代码基于成本优化程序确定的物理计划

DataSet：这本书编写时还未引入

Spark SQL  是最具有技术性的组件之一，因为他支持SQL查询和DataFrame API  ，其核心是Catalyst优化器。

优化器基于函数式编程结构，并且旨在实现两个目的： 简化向Spark SQL 添加新的优化技术和特性的条件 并允许外部开发肉疼元扩展优化器

1.3、spark 2.0 的架构   「略」
------------------------------------------------------------------


1.4、小结
------------------------------------------------------------------
提供了spark迆和API的基础

提供了RDD DataFrame、dataset入门  后面详细介绍DataFrame RDD 



