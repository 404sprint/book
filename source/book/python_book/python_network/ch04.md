第四章：HTTP协议网络编程
==============================================

`4.1、简介「略」`

`4.2、从HTTP服务器下载书籍`

```
# 从 HTTP 服务器下载数据

import argparse
import httplib

REMOTE_SERVER_HOST = 'www.baidu.com'
REMOTE_SERVER_PATH = '/'

class HTTPClient:
    def __init__(self, host):
        self.host = host

    def fetch(self, path):
        http = httplib.HTTP(self.host)
        # Prepare header
        http.putrequest("GET", path)
        http.putheader("User-Agent", __file__)
        http.putheader("Host", self.host)
        http.putheader("Accept", "*/*")
        http.endheaders()

        try:
            errcode, errmsg, headers = http.getreply()
        except Exception, e:
            print "Client failed error code: %s message: %s headers: %s" % (errcode, errmsg, headers)
        else:
            print "Got homepage from %s" % self.host

        file = http.getfile()
        return file.read()
    
if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='HTTP Client Example')
    parser.add_argument('--host', action="store", dest="host", default=REMOTE_SERVER_HOST)
    parser.add_argument('--path', action="store", dest="path", default=REMOTE_SERVER_PATH)
    given_args = parser.parse_args()
    host, path = given_args.host, given_args.path
    client = HTTPClient(host)
    print client.fetch(path)

```

`4.3、在你的设备中伺服HTTP请求`

```
# 在你的设备中伺服 HTTP 请求

import argparse
import sys
from BaseHTTPServer import BaseHTTPRequestHandler, HTTPServer

DEFAULT_HOST = '127.0.0.1'
DEFAULT_PORT = 8800

class RequestHandler(BaseHTTPRequestHandler):
    """Custom request handler"""
    def do_GET(self):
        """Handler for the GET requests"""
        self.send_response(200)
        self.send_header('Content-type', 'text/html')
        self.end_headers()
        # Send the message to browser
        self.wfile.write("Hello from server!")
        return

class CustomHTTPServer(HTTPServer):
    """A custom HTTP server"""
    def __init__(self, host, port):
        server_address = (host, port)
        HTTPServer.__init__(self, server_address, RequestHandler)

def run_server(port):
    try:
        server = CustomHTTPServer(DEFAULT_HOST, port)
        print "Custom HTTP server started on port: %s" % port
        server.serve_forever()
    except Exception, err:
        print "Error: %s" % err
    except KeyboardInterrupt:
        print "Server interrupted and is shutting down..."
        server.socket.close()
    
if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Simple HTTP Server Example')
    parser.add_argument('--port', action="store", dest="port", type=int, default=DEFAULT_PORT)
    given_args = parser.parse_args()
    port = given_args.port
    run_server(port)

```

`4.4、访问网站后提取cookie信息`

```
# 访问网站后提取 cookie 信息

import cookielib
import urllib
import urllib2

ID_USERNAME = 'username'
ID_PASSWORD = 'password'
USERNAME = ''
PASSWORD = ''
LOGIN_URL = 'https://bitbucket.org/account/signin/?next=/'
NORMAL_URL = 'https://bitbucket.org/'

def extract_cookie_info():
    """Fake login to a site with cookie"""
    # Setup cookie jar
    cj = cookielib.CookieJar()
    
    # Create url opener
    opener = urllib2.build_opener(urllib2.HTTPCookieProcessor(cj))
    opener.open(LOGIN_URL)

    try:
        token = [cookie.value for cookie in cj if cookie.name == 'csrftoken'][0]
    except IndexError:
        return False, "No csrftoken"
    
    login_data = urllib.urlencode({'csrfmiddlewaretoken': token, ID_USERNAME: USERNAME, ID_PASSWORD: PASSWORD, 'this_is_the_login_form': True})
    
    resp = opener.open(LOGIN_URL, login_data)

    # Send login info
    for cookie in cj:
        print '----First time cookie: %s --> %s' % (cookie.name, cookie.value)

    print "Headers: %s" % resp.headers

    # Now access without any login info
    resp = opener.open(NORMAL_URL)
    for cookie in cj:
        print "++++Second time cookie: %s --> %s" % (cookie.name, cookie.value)

    print "Headers: %s" % resp.headers

if __name__ == '__main__':
    extract_cookie_info()
```

`4.5、提交网页表单`

```
# 提交网页表单

import requests
import urllib
import urllib2
from lxml import html

ID_NAME = 'name'
ID_EMAIL = 'email'
ID_PASSWORD = 'password'
ID_CONFIRM = 'confirm'
ID_GPG_KEYID = 'gpg_keyid'
NAME = 'fortestzz3'
EMAIL = 'fortestzz3@163.com'
PASSWORD = 'fortestzz3fortestzz3'
CONFIRM = 'fortestzz3fortestzz3'
GPG_KEYID = ''

SIGNUP_URL = 'https://pypi.python.org/pypi'

def submit_form():
    """Submit a form"""
    payload = {
        ID_NAME: NAME,
        ID_EMAIL: EMAIL,
        ID_PASSWORD: PASSWORD,
        ID_CONFIRM: CONFIRM,
        ID_GPG_KEYID: GPG_KEYID,
        ':action': 'user'
    }
    
    # Make a GET request
    resp = requests.get(SIGNUP_URL)
    print "Response to GET request: %s" % resp.content

    # Send POST request
    resp = requests.post(SIGNUP_URL, payload)
    print resp.status_code
    print "Headers from a POST request response: %s" % resp.headers
    # print "HTML Response: %s" % resp.text
    
def submit_form_prefect():
    ses = requests.session()
    r = ses.get(SIGNUP_URL)
    cookies = r.cookies

    # 可以采用如下方式获取 token（如果 post 需要 token）
    # tree = html.fromstring(resp.text)
    # token = list(set(tree.xpath("//input[@name='token']/@value")))[0]
    
    payload = {
        ID_NAME: NAME,
        ID_EMAIL: EMAIL,
        ID_PASSWORD: PASSWORD,
        ID_CONFIRM: CONFIRM,
        ID_GPG_KEYID: GPG_KEYID,
        ':action': 'user'
    }
    
    headers = {
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
        'Accept-Encoding': 'gzip, deflate',
        'Accept-Language': 'zh-CN,zh;q=0.8,en-US;q=0.5,en;q=0.3',
        'Content-Length': '127',
        'Content-Type': 'application/x-www-form-urlencoded',
        'Connection': 'keep-alive',
        'Host': 'pypi.python.org',
        'Referer': 'https://pypi.python.org/pypi?:action=register_form',
        'Upgrade-Insecure-Requests': '1',
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:49.0) Gecko/20100101 Firefox/49.0'
    }

    # Send POST request
    resp = ses.post(SIGNUP_URL, data=payload, headers=headers, cookies=cookies)
    print resp.status_code
    print "Headers from a POST request response: %s" % resp.headers

if __name__ == '__main__':
    submit_form()
```

`4.6、通过代理服务器发送WEB请求`

```
# 通过代理服务器发送 Web 请求

import urllib

URL = 'https://www.github.com'
PROXY_ADDRESS = '1.164.144.107:8080'    # Get from http://www.xicidaili.com/

if __name__ == '__main__':
    resp = urllib.urlopen(URL, proxies = {"http": PROXY_ADDRESS})
    print "Proxy server returns response headers: %s" % resp.headers
```

`4.7、使用HEAD请求检查网页是否存在`

```
import argparse
import httplib
import urlparse
import re
import urllib

DEFAULT_URL = 'http://www.python.org'
HTTP_GOOD_CODES = [httplib.OK, httplib.FOUND, httplib.MOVED_PERMANENTLY]

def get_server_status_code(url):
    """Download just the header of a URL and return the server's status code"""
    print urlparse.urlparse(url)
    host, path = urlparse.urlparse(url)[1:3]
    print host, path
    try:
        conn = httplib.HTTPConnection(host)
        conn.request('HEAD', path)
        return conn.getresponse().status
    except StandardError, err:
        print err
        return None

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Example HEAD Request')
    parser.add_argument('--url', action="store", dest="url", default=DEFAULT_URL)
    given_args = parser.parse_args()
    url = given_args.url
    if get_server_status_code(url) in HTTP_GOOD_CODES:
        print "Server: %s status is OK." % url
    else:
        print "Server: %s status is NOT OK." % url
```

`4.8、把客户端伪装成Mozilla Firefox`

```
# 把客户端伪装成 Mozilla Firefox

import urllib2

BROWSER = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:49.0) Gecko/20100101 Firefox/49.0'
URL = 'http://www.python.org'

def spoof_firefox():
    opener = urllib2.build_opener()
    opener.addheaders = [('User-agent', BROWSER)]
    result = opener.open(URL)
    print "Response headers:"
    for header in result.headers.headers:
        print "\t", header

if __name__ == '__main__':
    spoof_firefox()
```

`4.9、使用HTTP压缩节约Web请求消耗的带宽`

```
# 使用 HTTP 压缩节省 Web 请求消耗的带宽

import argparse
import string
import os
import sys
import gzip
import cStringIO
from BaseHTTPServer import BaseHTTPRequestHandler, HTTPServer

DEFAULT_HOST = '127.0.0.1'
DEFAULT_PORT = 8800
HTML_CONTENT = """<html><body><h1>Compressed Hello World!</h1></body></html>"""

class RequestHandler(BaseHTTPRequestHandler):
    """Custom request handler"""
    def do_GET(self):
        """Handler for the GET requests"""
        self.send_response(200)
        self.send_header('Content-type', 'text/html')
        self.send_header('Content-Encoding', 'gzip')
        zbuf = self.compress_buffer(HTML_CONTENT)
        sys.stdout.write("Content-Encoding: gzip\r\n")
        self.send_header('Content-Length', len(zbuf))
        self.end_headers()

        # Send the message to browser
        zbuf = self.compress_buffer(HTML_CONTENT)
        sys.stdout.write("Content-Encoding: gzip\r\n")
        sys.stdout.write("Content-Length: %d\r\n" % (len(zbuf)))
        sys.stdout.write("\r\n")
        self.wfile.write(zbuf)
        return

    def compress_buffer(self, buf):
        zbuf = cStringIO.StringIO()
        zfile = gzip.GzipFile(mode='wb', fileobj=zbuf, compresslevel=6)
        zfile.write(buf)
        zfile.close()
        return zbuf.getvalue()

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Simple HTTP Server Example')
    parser.add_argument('--port', action="store", dest="port", type=int, default=DEFAULT_PORT)
    given_args = parser.parse_args()
    port = given_args.port
    server_address = (DEFAULT_HOST, port)
    server = HTTPServer(server_address, RequestHandler)
    server.serve_forever()
```

`4.10、编写一个支持断点续传的HTTP容错客户端`

```
# 编写一个支持断点续传功能的 HTTP 容错客户端

import urllib
import os

TARGET_URL = 'http://www.embeddedsystem.org/crosstool/5.2.0/'
TARGET_FILE = 'crosstool-5.2.0.tar.bz2'

class CustomURLOpener(urllib.FancyURLopener):
    """Override FancyURLopener to skip error 206 (when a partial file is being sent)"""
    def http_error_206(self, url, fp, errcode, errmsg, headers, data=None):
        pass

def resume_download():
    file_exists = False
    CustomURLClass = CustomURLOpener()
    if os.path.exists(TARGET_FILE):
        out_file = open(TARGET_FILE, 'ab')
        file_exists = os.path.getsize(TARGET_FILE)
        # If the file exists, then only download the unfinished part
        CustomURLClass.addheader("range", "bytes=%s-" % (file_exists))
    else:
        out_file = open(TARGET_FILE, 'wb')

    web_page = CustomURLClass.open(TARGET_URL + TARGET_FILE)

    # Check if last download was OK
    if int(web_page.headers['Content-Length']) == file_exists:
        loop = 0
        print "File already downloaded!"

    byte_count = 0
    while True:
        data = web_page.read(8192)
        if not data:
            break
        out_file.write(data)
        byte_count = byte_count + len(data)

    web_page.close()
    out_file.close()

    for k, v in web_page.headers.items():
        print k, '=', v
    print "File copied", byte_count, "bytes from", web_page.url

if __name__ == '__main__':
    resume_download()

```

`4.11、使用Python和OpenSSL编写一个简单的HTTPS服务器`

```
# 使用 Python 和 OpenSSL 编写一个简单的 HTTPS 服务器

import socket
import os
import sys
from SocketServer import BaseServer
from BaseHTTPServer import HTTPServer
from SimpleHTTPServer import SimpleHTTPRequestHandler
from OpenSSL import SSL, crypto
from random import random

TARGET_URL = 'http://www.python.org/ftp/python/2.7.4/'
TARGET_FILE = 'Python-2.7.4.tgz'

class SecureHTTPServer(HTTPServer):
    def __init__(self, server_address, HandlerClass):
        BaseServer.__init__(self, server_address, HandlerClass)

        ctx = SSL.Context(SSL.SSLv23_METHOD)
        
        # Location of the server private key and the server certificate
        # 生成两个证书
        # openssl req -x509 -newkey rsa:2048 -keyout pkey.pem -out cert.pem -days 365
        # ctx.use_privatekey_file('pkey.pem')
        # ctx.use_certificate_file('cert.pem')

        # 生成一个证书
        # openssl req -new -x509 -keyout server.pem -out server.pem -days 365 -nodes
        fpem = 'server.pem'
        ctx.use_privatekey_file(fpem)
        ctx.use_certificate_file(fpem)
        
        self.socket = SSL.Connection(ctx, socket.socket(self.address_family, self.socket_type))
        self.server_bind()
        self.server_activate()

    def shutdown_request(self, request):
        request.shutdown()

class SecureHTTPRequestHandler(SimpleHTTPRequestHandler):
    def setup(self):
        self.connection = self.request
        self.rfile = socket._fileobject(self.request, "rb", self.rbufsize)
        self.wfile = socket._fileobject(self.request, "wb", self.wbufsize)

    def do_GET(self):
        """Handler for the GET requests"""
        self.send_response(200)
        self.send_header('Content-type', 'text/html')
        self.end_headers()
        # Send the message to browser
        self.wfile.write("Hello from https server!")
        return

def run_server(HandlerClass=SecureHTTPRequestHandler, ServerClass=SecureHTTPServer):
    server_address = ('', 4443)    # port needs to be accessible by user
    server = ServerClass(server_address, HandlerClass)
    running_address = server.socket.getsockname()
    print "Serving HTTPS Server on %s:%s ..." % (running_address[0], running_address[1])
    server.serve_forever()

if __name__ == '__main__':
    run_server()

```

